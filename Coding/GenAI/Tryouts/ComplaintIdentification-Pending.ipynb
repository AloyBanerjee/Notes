{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "import numpy as np \n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set OpenAI API key\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
    "\n",
    "# Prepare documents (complaints and non-complaints examples)\n",
    "documents = [\n",
    "    Document(page_content=\"Complaint: The device malfunctioned during surgery, causing patient discomfort.\"),\n",
    "    Document(page_content=\"Complaint: The catheter was defective and led to an infection.\"),\n",
    "    Document(page_content=\"Complaint: The device failed to operate as specified, resulting in an adverse event.\"),\n",
    "    Document(page_content=\"Non-Complaint: The training manual was helpful in understanding the device operation.\"),\n",
    "    Document(page_content=\"Non-Complaint: The product arrived on time and worked as expected.\"),\n",
    "    Document(page_content=\"Non-Complaint: The customer service team provided excellent support.\"),\n",
    "]\n",
    "\n",
    "# Generate embeddings and index them with FAISS\n",
    "faiss_index = FAISS.from_documents(documents, embeddings)\n",
    "faiss_index.save_local(\"med_tech_faiss_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAISS index\n",
    "faiss_index = FAISS.load_local(\"med_tech_faiss_index\", embeddings, allow_dangerous_deserialization = True)\n",
    "\n",
    "def classify_text(text: str):\n",
    "    \"\"\"\n",
    "    Classifies a given text as Complaint or Non-Complaint using similarity search.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to classify.\n",
    "    \n",
    "    Returns:\n",
    "        str: The classification (Complaint or Non-Complaint).\n",
    "    \"\"\"\n",
    "    # Search for the most similar document\n",
    "    results = faiss_index.similarity_search(text, k=1)\n",
    "    \n",
    "    if results:\n",
    "        # Extract the most similar document\n",
    "        closest_match = results[0].page_content\n",
    "        return \"Complaint\" if \"Complaint\" in closest_match else \"Non-Complaint\"\n",
    "    else:\n",
    "        return \"Unable to classify\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: Complaint\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "text_to_classify = \"The device broke during usage, leading to a patient injury.\"\n",
    "text_to_classify1 = \"I am suffering from fever but I am ok now.\"\n",
    "classification = classify_text(text_to_classify)\n",
    "print(f\"Classification: {classification}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_similarity(text: str):\n",
    "    \"\"\"\n",
    "    Computes similarity between the input text and indexed documents.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to compare.\n",
    "    \n",
    "    Returns:\n",
    "        List[Tuple[str, float]]: A list of documents with their similarity scores.\n",
    "    \"\"\"\n",
    "    input_embedding = embeddings.embed_query(text)\n",
    "    indexed_embeddings = faiss_index.index.reconstruct_n(0, len(faiss_index.index))\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarities = np.dot(indexed_embeddings, input_embedding) / (\n",
    "        np.linalg.norm(indexed_embeddings, axis=1) * np.linalg.norm(input_embedding)\n",
    "    )\n",
    "    \n",
    "    # Retrieve the documents with similarity scores\n",
    "    docs_with_scores = [\n",
    "        (doc.page_content, score)\n",
    "        for doc, score in zip(faiss_index.similarity_search_with_score(text, k=len(documents)), similarities)\n",
    "    ]\n",
    "    return sorted(docs_with_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Compute similarities for the text\n",
    "similarity_results = compute_similarity(text_to_classify)\n",
    "for doc, score in similarity_results:\n",
    "    print(f\"Document: {doc} | Similarity: {score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
