{"cells":[{"cell_type":"markdown","id":"dcd0b393","metadata":{"id":"dcd0b393"},"source":["### Deep Learning - Assignment 3 - CH22M503"]},{"cell_type":"markdown","id":"7126b5cb","metadata":{"id":"7126b5cb"},"source":["#### Author - Aloy Banerjee\n","###### Roll No. CH22M503"]},{"cell_type":"markdown","id":"e50f5c7d","metadata":{"id":"e50f5c7d"},"source":["##  Multilayer Perceptrons in PyTorch and Sklearn\n","#### 1. This entire assignment must be completed in a jupyter notebook. Specifically, use Google Colab to do all your coding and then download the resultant notebook (with the outputs still in the cells) as an ipynb file and submit the same. Using Google Colab is recommended as it will ensure some level of uniformity in hardware and therefore ease the evaluation process.\n","#### 2. We will be using sklearn and PyTorch for our neural networks. Using Tensorflow for neural networks is not allowed for this assignment.\n","#### 3. For uniformity, please use this piece of code as the first cell of your notebook and make sure you run this cell before   any other cells are run (If this cell is not present in your submission, you will be awarded 0 marks):\n","#### def seed_everything(seed=42):\n","####     random.seed(seed)\n","####     os.environ['PYTHONHASHSEED']=str(seed)\n","####     np.random.seed(seed)\n","####     torch.manual_seed(seed)\n","####     torch.use_deterministic_algorithms(True)\n","#### seed_everything(seed=42)\n","#### 4. In this assignment our goal is to code a multi layer perceptron including backpropagation and gradient descent using Pytorch. Since Pytorch takes care of backpropagation and gradient descent, we are primarily concerned with the code for forward pass and model building. We will not be using any Pytorch DataLoaders in this exercise.\n","#### 5. The dataset to be used is the MNIST dataset. The dataset can be loaded with the following code:\n","#### from tensorflow.keras.datasets import mnist\n","#### (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n","#### 6. Please split the X_train and Y_train data further using sklearn‚Äôs train_test_split function with random_state as 42 and test_size as 0.20 to get the new X_train and Y_train and also X_val and Y_val.\n","#### 7. Using matplotlib.pyplot.imshow, display the first image in the X_train numpy array and the corresponding label from the Y_train numpy array (This label should be printed in the next cell). Set the cmap parameter of this imshow function as \"gray\".\n","#### 8. The network architecture is as follows:\n","##### a. A Linear Layer with number of input features as 784 and number of output features as 16\n","##### b. A Non Linear Activation of ReLU\n","##### c. A Linear Layer with number of input features as 16 and number of output features as 32\n","##### d. A Non Linear Activation of ReLU\n","##### e. A Linear Layer with number of input features as 32 and number of output features as 16\n","##### f. A Non Linear Activation of LeakyReLU\n","##### g. A Linear Layer with number of input features as 16 and number of output features as 10\n","##### h. An appropriate layer that finally gives us probabilities of the different classes. Choose this layer yourself. There is only one correct answer.\n","\n","#### 9. Make sure that you make a python class for the PyTorch model.\n","#### 10. The optimizer for this exercise will be the Adam Optimizer. Keep the learning rate of the optimizer as 1e-2.\n","#### 11. The loss function for this will be the CrossEntropyLoss already implemented in PyTorch. You should not write your own Cross Entropy Loss module.\n","#### 12. Make a separate python class that will be used for training this model.Train this model for such that it sees each data point exactly 1000 times. Make sure you print the training loss every 50th time the full dataset is seen. If the the prints of your loss are not present, marks will be deducted.\n","#### 13. Post training this model, use it to make predictions on all the three different sets of data we have which are the training set (ùëã_ùë°ùëüùëéùëñùëõ,ùëå_ùë°ùëüùëéùëñùëõ), validation set (ùëã_ùë£ùëéùëô,ùëå_ùë£ùëéùëô), testing set (ùëã_ùë°ùëíùë†ùë°,ùëå_ùë°ùëíùë†ùë°).\n","#### 14. Based on the predictions, find the precision, recall and f1 score for all the different classes (which are the digits). Also report the accuracies for each class and report a weighted average accuracy across all classes. Using any sklearn functions for this task is not allowed.\n","#### 15. Now, we will do the same exercise with sklearn. Use the MLPClassifier class from sklearn. Using this class, keep the architecture of the hidden layers as the same as previously mentioned in point 8. Sklearn automatically adjusts and recognises the input sizes for the input and output layer of the neural network. Use relu as the activation for all layers and use the random_state value as 42. Do not change any other parameters of the class.\n","#### 16. Fit the class to the X_train and Y_train data.\n","#### 17. Use the fitted class to make predictions on the three datasets mentioned in point 13.\n","#### 18. Create classification reports using sklearn.metrics.classification_report for the different sets of predictions."]},{"cell_type":"markdown","id":"0e2632a8","metadata":{"id":"0e2632a8"},"source":["#### Reference"]},{"cell_type":"code","execution_count":1,"id":"441fc812","metadata":{"id":"441fc812","executionInfo":{"status":"ok","timestamp":1679117205913,"user_tz":-330,"elapsed":5,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["# https://github.com/fadilparves/pytorch-ann/blob/main/main.py"]},{"cell_type":"markdown","id":"a9052f85","metadata":{"id":"a9052f85"},"source":["#### Importing Library"]},{"cell_type":"code","execution_count":2,"id":"346d244a","metadata":{"id":"346d244a","executionInfo":{"status":"ok","timestamp":1679117211345,"user_tz":-330,"elapsed":5435,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["import random\n","import os\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","from sklearn.neural_network import MLPClassifier\n","from tensorflow.keras.datasets import mnist\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"]},{"cell_type":"markdown","id":"3e2c2314","metadata":{"id":"3e2c2314"},"source":["#### Define the constant value"]},{"cell_type":"code","execution_count":3,"id":"2913c977","metadata":{"id":"2913c977","executionInfo":{"status":"ok","timestamp":1679117211345,"user_tz":-330,"elapsed":15,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["epochs = 1000\n","seed = 42\n","round_precesion = 2"]},{"cell_type":"markdown","id":"de003d50","metadata":{"id":"de003d50"},"source":["#### Common Method"]},{"cell_type":"code","execution_count":4,"id":"2294d8bb","metadata":{"id":"2294d8bb","executionInfo":{"status":"ok","timestamp":1679117211346,"user_tz":-330,"elapsed":16,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["def seed_everything(seed=seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED']=str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.use_deterministic_algorithms(True)\n","    \n","def data_load():\n","    (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n","    X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=seed)\n","    return X_train, X_val, X_test, Y_train, Y_val, Y_test\n","\n","def normalize_data(X):\n","    return X.astype('float32') / 255.\n","\n","def one_hot_encode_labels(Y):\n","    return np.eye(10)[Y]\n","\n","def flatten_array(X):\n","    return X.reshape((len(X), np.prod(X.shape[1:])))\n","\n","def data_normalize(X_train, X_validation, X_test, Y_train, Y_validation, Y_test):\n","    # Normalize the input images\n","    X_train = normalize_data(X_train)\n","    X_validation = normalize_data(X_validation)\n","    X_test = normalize_data(X_test)\n","    # Convert the labels to one-hot encoding\n","    Y_train = one_hot_encode_labels(Y_train)\n","    Y_validation = one_hot_encode_labels(Y_validation)\n","    Y_test = one_hot_encode_labels(Y_test)\n","    return X_train, X_validation, X_test, Y_train, Y_validation, Y_test\n","\n","def flatten_data(X_train,X_val,X_test):\n","    X_train = flatten_array(X_train)\n","    X_val = flatten_array(X_val)\n","    X_test = flatten_array(X_test)\n","    return X_train, X_val, X_test    \n","\n","def get_classification_metrics(actual_labels, predicted_labels):\n","    unique_labels = np.sort(np.unique(actual_labels))\n","    actual_labels_np = actual_labels.numpy()\n","    predicted_labels_np = predicted_labels.numpy()\n","    confusion_matrix = np.zeros((len(unique_labels), len(unique_labels)))\n","    classification_report = np.zeros((len(unique_labels), 5))    \n","    # Calculate confusion matrix\n","    for i in range(len(unique_labels)):\n","        for j in range(len(unique_labels)):\n","            confusion_matrix[i, j] = np.sum((actual_labels_np == unique_labels[i]) & (predicted_labels_np == unique_labels[j]))            \n","    # Calculate category accuracy\n","    category_accuracy = confusion_matrix.diagonal() / confusion_matrix.sum(axis=1)    \n","    weighted_acc = 0\n","    # Calculate metrics for each category\n","    for j in range(len(unique_labels)):        \n","        actual_label, predicted_label = (actual_labels_np == unique_labels[j]), (predicted_labels_np == unique_labels[j])\n","        true_positives, false_positives, false_negatives = np.sum(actual_label & predicted_label), np.sum(~actual_label & predicted_label), np.sum(actual_label & ~predicted_label)\n","        count = np.sum(actual_labels_np == unique_labels[j])\n","        precision = true_positives / (true_positives + false_positives)\n","        recall = true_positives / (true_positives + false_negatives)\n","        f1_score = 2 * (precision * recall) / (precision + recall) \n","        classification_report[j, :] = np.round([precision, recall, f1_score, category_accuracy[j], count], round_precesion)\n","        weighted_acc += (f1_score * count)        \n","    weighted_acc = weighted_acc / len(actual_labels)    \n","    return weighted_acc, classification_report"]},{"cell_type":"markdown","id":"436a1a16","metadata":{"id":"436a1a16"},"source":["#### Seed everything "]},{"cell_type":"code","execution_count":5,"id":"c4dbb5a3","metadata":{"id":"c4dbb5a3","executionInfo":{"status":"ok","timestamp":1679117211346,"user_tz":-330,"elapsed":15,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["seed_everything(seed=seed)"]},{"cell_type":"markdown","id":"bc44d24c","metadata":{"id":"bc44d24c"},"source":["#### 6. Please split the X_train and Y_train data further using sklearn‚Äôs train_test_split function with random_state as 42 and test_size as 0.20 to get the new X_train and Y_train and also X_val and Y_val"]},{"cell_type":"markdown","id":"a7a13e96","metadata":{"id":"a7a13e96"},"source":["#### Train test and validation data split "]},{"cell_type":"code","execution_count":6,"id":"b18e4c59","metadata":{"id":"b18e4c59","executionInfo":{"status":"ok","timestamp":1679117213149,"user_tz":-330,"elapsed":1818,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"87363119-d9b7-45ad-e6c5-44723d2aa732"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]}],"source":["X_train, X_val, X_test, Y_train, Y_val, Y_test = data_load()"]},{"cell_type":"markdown","id":"912ead5c","metadata":{"id":"912ead5c"},"source":["#### Verify the dimention of the data"]},{"cell_type":"code","execution_count":7,"id":"8814fa8a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8814fa8a","outputId":"c79bcdde-1642-4195-d7e4-43274028d0c9","executionInfo":{"status":"ok","timestamp":1679117213149,"user_tz":-330,"elapsed":23,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train Shape : (48000, 28, 28)\n","X_val Shape : (12000, 28, 28)\n","X_test Shape : (10000, 28, 28)\n","Y_train Shape : (48000,)\n","Y_val Shape : (12000,)\n","Y_test Shape : (10000,)\n"]}],"source":["print(f'X_train Shape : {X_train.shape}')\n","print(f'X_val Shape : {X_val.shape}')\n","print(f'X_test Shape : {X_test.shape}')\n","print(f'Y_train Shape : {Y_train.shape}')\n","print(f'Y_val Shape : {Y_val.shape}')\n","print(f'Y_test Shape : {Y_test.shape}')"]},{"cell_type":"markdown","id":"94a16caa","metadata":{"id":"94a16caa"},"source":["#### 7. Using matplotlib.pyplot.imshow, display the first image in the X_train numpy array and the corresponding label from the Y_train numpy array (This label should be printed in the next cell). Set the cmap parameter of this imshow function as \"gray\"."]},{"cell_type":"code","execution_count":8,"id":"ELDddupaPx2s","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265},"id":"ELDddupaPx2s","outputId":"d22300a4-5d62-4bf2-fd3f-579cd836cacc","executionInfo":{"status":"ok","timestamp":1679117213150,"user_tz":-330,"elapsed":22,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["plt.imshow(X_train[0], cmap='gray')\n","plt.show()"]},{"cell_type":"code","execution_count":9,"id":"c72ab245","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c72ab245","outputId":"bcd4c5f5-2870-4c4f-b860-57cf316d6f7a","executionInfo":{"status":"ok","timestamp":1679117213150,"user_tz":-330,"elapsed":20,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Label:  5\n"]}],"source":["print(\"Label: \", Y_train[0])"]},{"cell_type":"markdown","id":"beb3b243","metadata":{"id":"beb3b243"},"source":["#### 8. The network architecture is as follows:\n","##### a. A Linear Layer with number of input features as 784 and number of output features as 16\n","##### b. A Non Linear Activation of ReLU\n","##### c. A Linear Layer with number of input features as 16 and number of output features as 32\n","##### d. A Non Linear Activation of ReLU\n","##### e. A Linear Layer with number of input features as 32 and number of output features as 16\n","##### f. A Non Linear Activation of LeakyReLU\n","##### g. A Linear Layer with number of input features as 16 and number of output features as 10\n","##### h. An appropriate layer that finally gives us probabilities of the different classes. Choose this layer yourself. There is only one correct answer."]},{"cell_type":"code","execution_count":10,"id":"abb4867e","metadata":{"id":"abb4867e","executionInfo":{"status":"ok","timestamp":1679117213150,"user_tz":-330,"elapsed":18,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["class MLP(nn.Module):\n","    \n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.linear1 = nn.Linear(in_features = 784, out_features = 16)        \n","        self.linear2 = nn.Linear(in_features = 16, out_features = 32)        \n","        self.linear3 = nn.Linear(in_features = 32, out_features = 16)        \n","        self.linear4 = nn.Linear(in_features = 16, out_features = 10)\n","        self.relu1 = nn.ReLU()\n","        self.relu2 = nn.ReLU()\n","        self.leakyrelu = nn.LeakyReLU()\n","        #Commented out because CrossEntropyLoss criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n","        #https://discuss.pytorch.org/t/need-help-pytorch-softmax-cross-entropy-loss-function/146243 \n","        #self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        out = self.linear1(x)\n","        out = self.relu1(out)\n","        out = self.linear2(out)\n","        out = self.relu2(out)\n","        out = self.linear3(out)\n","        out = self.leakyrelu(out)\n","        out = self.linear4(out)\n","        #Commented out because CrossEntropyLoss criterion combines nn.LogSoftmax() and nn.NLLLoss() in one single class.\n","        #https://discuss.pytorch.org/t/need-help-pytorch-softmax-cross-entropy-loss-function/146243 \n","        #out = self.softmax(out)\n","        return out"]},{"cell_type":"markdown","id":"8eaf111c","metadata":{"id":"8eaf111c"},"source":["#### Normalize and flatten the data set before feed into neural network"]},{"cell_type":"code","execution_count":11,"id":"f486d86d","metadata":{"id":"f486d86d","executionInfo":{"status":"ok","timestamp":1679117213931,"user_tz":-330,"elapsed":798,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["# Normalize the images and one hot encoded\n","X_train, X_val, X_test, Y_train, Y_val, Y_test = data_normalize(X_train, X_val, X_test, Y_train, Y_val, Y_test)\n","# Flatten the images\n","X_train,X_val,X_test = flatten_data(X_train,X_val,X_test)"]},{"cell_type":"code","execution_count":12,"id":"5a3082a3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5a3082a3","outputId":"f88fc05e-8954-4721-bce2-f9bbf7c14247","executionInfo":{"status":"ok","timestamp":1679117213932,"user_tz":-330,"elapsed":15,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["X_train Shape : (48000, 784)\n","X_validation Shape : (12000, 784)\n","X_test Shape : (10000, 784)\n"]}],"source":["print(f'X_train Shape : {X_train.shape}')\n","print(f'X_validation Shape : {X_val.shape}')\n","print(f'X_test Shape : {X_test.shape}')"]},{"cell_type":"markdown","id":"efc81126","metadata":{"id":"efc81126"},"source":["#### 10. The optimizer for this exercise will be the Adam Optimizer. Keep the learning rate of the optimizer as 1e-2.\n","#### 11. The loss function for this will be the CrossEntropyLoss already implemented in PyTorch. You should not write your own Cross Entropy Loss module.\n","#### 12. Make a separate python class that will be used for training this model.Train this model for such that it sees each data point exactly 1000 times. Make sure you print the training loss every 50th time the full dataset is seen. If the the prints of your loss are not present, marks will be deducted."]},{"cell_type":"markdown","id":"6f654f0a","metadata":{"id":"6f654f0a"},"source":["#####     Accuracy = Correct Predictions / Total Cases * 100%\n","#####     Precision = TP / (TP + FP) * 100%\n","#####     Recall = TP / TP + FN.\n","#####     F1 Score = 2 * Precision * Recall / Precision + Recall."]},{"cell_type":"code","execution_count":13,"id":"d662056c","metadata":{"id":"d662056c","executionInfo":{"status":"ok","timestamp":1679117213933,"user_tz":-330,"elapsed":12,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["class Trainer:\n","    \n","    def __init__(self, model, train_data, val_data, test_data):\n","        self.model = model\n","        self.train_data = train_data\n","        self.val_data = val_data\n","        self.test_data = test_data\n","        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-2)\n","        self.criterion = nn.CrossEntropyLoss()\n","\n","    def train(self, epochs):\n","        running_loss = 0.0  \n","        for epoch in range(epochs):            \n","            data = self.train_data\n","            inputs, labels = torch.tensor(data[0]),torch.tensor(data[1])\n","            self.optimizer.zero_grad()\n","            outputs = self.model(inputs)\n","            loss = self.criterion(outputs, labels)\n","            loss.backward()\n","            self.optimizer.step()\n","            running_loss += loss.item()\n","            if epoch % 50 == 49:\n","                print(f\"Epoch : {epoch+1}, Average Loss : {np.round(running_loss/len(self.train_data),round_precesion)}, Training Loss : {np.round(loss.item(),round_precesion)}, Running Loss : {np.round(running_loss,round_precesion)}\")\n","                print('==================================================================================')\n","\n","    def test(self, data):\n","        with torch.no_grad():\n","            inputs, labels = torch.tensor(data[0]),data[1]\n","            outputs = self.model(inputs)           \n","            _, predicted = torch.max(outputs.data, 1)            \n","            labels = torch.tensor(labels)\n","            labels_recons = np.argmax(labels, axis=1)\n","            weighted_acc, report = get_classification_metrics(labels_recons, predicted)\n","            #print('Weighted Accuracy: ', weighted_acc, '\\nReport: ', report)\n","            return predicted, weighted_acc, report\n","        "]},{"cell_type":"markdown","id":"ae5f017d","metadata":{"id":"ae5f017d"},"source":["#### 13. Post training this model, use it to make predictions on all the three different sets of data we have which are the training set (ùëã_ùë°ùëüùëéùëñùëõ,ùëå_ùë°ùëüùëéùëñùëõ), validation set (ùëã_ùë£ùëéùëô,ùëå_ùë£ùëéùëô), testing set (ùëã_ùë°ùëíùë†ùë°,ùëå_ùë°ùëíùë†ùë°).\n","#### 14. Based on the predictions, find the precision, recall and f1 score for all the different classes (which are the digits).Also report the accuracies for each class and report a weighted average accuracy across all classes. Using anysklearn functions for this task is not allowed."]},{"cell_type":"code","execution_count":14,"id":"100f3590","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"100f3590","outputId":"96e8cf30-fd13-4b88-bc35-a58627dfd60c","executionInfo":{"status":"ok","timestamp":1679117391310,"user_tz":-330,"elapsed":177388,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch : 50, Average Loss : 24.56, Training Loss : 0.34, Running Loss : 49.13\n","==================================================================================\n","Epoch : 100, Average Loss : 30.81, Training Loss : 0.2, Running Loss : 61.61\n","==================================================================================\n","Epoch : 150, Average Loss : 35.14, Training Loss : 0.15, Running Loss : 70.27\n","==================================================================================\n","Epoch : 200, Average Loss : 38.54, Training Loss : 0.12, Running Loss : 77.08\n","==================================================================================\n","Epoch : 250, Average Loss : 41.32, Training Loss : 0.1, Running Loss : 82.64\n","==================================================================================\n","Epoch : 300, Average Loss : 43.61, Training Loss : 0.08, Running Loss : 87.22\n","==================================================================================\n","Epoch : 350, Average Loss : 45.58, Training Loss : 0.07, Running Loss : 91.16\n","==================================================================================\n","Epoch : 400, Average Loss : 47.43, Training Loss : 0.11, Running Loss : 94.86\n","==================================================================================\n","Epoch : 450, Average Loss : 49.15, Training Loss : 0.06, Running Loss : 98.3\n","==================================================================================\n","Epoch : 500, Average Loss : 50.48, Training Loss : 0.05, Running Loss : 100.97\n","==================================================================================\n","Epoch : 550, Average Loss : 51.72, Training Loss : 0.05, Running Loss : 103.44\n","==================================================================================\n","Epoch : 600, Average Loss : 53.74, Training Loss : 0.12, Running Loss : 107.47\n","==================================================================================\n","Epoch : 650, Average Loss : 55.75, Training Loss : 0.05, Running Loss : 111.51\n","==================================================================================\n","Epoch : 700, Average Loss : 56.84, Training Loss : 0.04, Running Loss : 113.68\n","==================================================================================\n","Epoch : 750, Average Loss : 57.78, Training Loss : 0.04, Running Loss : 115.55\n","==================================================================================\n","Epoch : 800, Average Loss : 58.61, Training Loss : 0.03, Running Loss : 117.22\n","==================================================================================\n","Epoch : 850, Average Loss : 59.36, Training Loss : 0.03, Running Loss : 118.72\n","==================================================================================\n","Epoch : 900, Average Loss : 60.04, Training Loss : 0.03, Running Loss : 120.08\n","==================================================================================\n","Epoch : 950, Average Loss : 61.17, Training Loss : 0.82, Running Loss : 122.33\n","==================================================================================\n","Epoch : 1000, Average Loss : 71.27, Training Loss : 0.14, Running Loss : 142.55\n","==================================================================================\n"]}],"source":["model = MLP()\n","trainer = Trainer(model, [X_train,Y_train], [X_val,Y_val], [X_test,Y_test])\n","trainer.train(epochs)   "]},{"cell_type":"code","execution_count":15,"id":"18d267ed","metadata":{"id":"18d267ed","executionInfo":{"status":"ok","timestamp":1679117391311,"user_tz":-330,"elapsed":15,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["#Train\n","train_predicted, train_weighted_acc, train_report = trainer.test([X_train,Y_train])\n","#Validation\n","val_predicted, val_weighted_acc, val_report = trainer.test([X_val,Y_val])\n","#Test\n","test_predicted, test_weighted_acc, test_report = trainer.test([X_test,Y_test])"]},{"cell_type":"code","execution_count":16,"id":"EDdWbDFzEDTl","metadata":{"id":"EDdWbDFzEDTl","executionInfo":{"status":"ok","timestamp":1679117391311,"user_tz":-330,"elapsed":14,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["df_result_train = pd.DataFrame(train_report, columns = ['Precision','Recall','F1 - Score', 'Accuracy - Category wise', 'Count - Category wise'])\n","df_result_validation = pd.DataFrame(val_report, columns = ['Precision','Recall','F1 - Score', 'Accuracy - Category wise', 'Count - Category wise'])\n","df_result_test = pd.DataFrame(test_report, columns = ['Precision','Recall','F1 - Score', 'Accuracy - Category wise', 'Count - Category wise'])"]},{"cell_type":"code","execution_count":17,"id":"vsUxNKrqFGAM","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vsUxNKrqFGAM","outputId":"dfc6be6a-dcc4-40f2-9815-e2c4a06b2d0a","executionInfo":{"status":"ok","timestamp":1679117391311,"user_tz":-330,"elapsed":14,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Training Set - Report\n","Train Weighted Accuracy 0.9559300088197356\n"]},{"output_type":"display_data","data":{"text/plain":["   Precision  Recall  F1 - Score  Accuracy - Category wise  \\\n","0       0.97    0.98        0.98                      0.98   \n","1       0.98    0.98        0.98                      0.98   \n","2       0.97    0.95        0.96                      0.95   \n","3       0.94    0.94        0.94                      0.94   \n","4       0.95    0.96        0.95                      0.96   \n","5       0.95    0.93        0.94                      0.93   \n","6       0.97    0.98        0.97                      0.98   \n","7       0.97    0.96        0.97                      0.96   \n","8       0.93    0.94        0.93                      0.94   \n","9       0.93    0.94        0.94                      0.94   \n","\n","   Count - Category wise  \n","0                 4748.0  \n","1                 5420.0  \n","2                 4784.0  \n","3                 4912.0  \n","4                 4666.0  \n","5                 4317.0  \n","6                 4741.0  \n","7                 4966.0  \n","8                 4691.0  \n","9                 4755.0  "],"text/html":["\n","  <div id=\"df-c04db9a8-8cbd-4d12-bad9-3a5a017dbe96\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 - Score</th>\n","      <th>Accuracy - Category wise</th>\n","      <th>Count - Category wise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.97</td>\n","      <td>0.98</td>\n","      <td>0.98</td>\n","      <td>0.98</td>\n","      <td>4748.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.98</td>\n","      <td>0.98</td>\n","      <td>0.98</td>\n","      <td>0.98</td>\n","      <td>5420.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.97</td>\n","      <td>0.95</td>\n","      <td>0.96</td>\n","      <td>0.95</td>\n","      <td>4784.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.94</td>\n","      <td>0.94</td>\n","      <td>0.94</td>\n","      <td>0.94</td>\n","      <td>4912.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.95</td>\n","      <td>0.96</td>\n","      <td>0.95</td>\n","      <td>0.96</td>\n","      <td>4666.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.95</td>\n","      <td>0.93</td>\n","      <td>0.94</td>\n","      <td>0.93</td>\n","      <td>4317.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.97</td>\n","      <td>0.98</td>\n","      <td>0.97</td>\n","      <td>0.98</td>\n","      <td>4741.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.97</td>\n","      <td>0.96</td>\n","      <td>0.97</td>\n","      <td>0.96</td>\n","      <td>4966.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.93</td>\n","      <td>0.94</td>\n","      <td>0.93</td>\n","      <td>0.94</td>\n","      <td>4691.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.93</td>\n","      <td>0.94</td>\n","      <td>0.94</td>\n","      <td>0.94</td>\n","      <td>4755.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c04db9a8-8cbd-4d12-bad9-3a5a017dbe96')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c04db9a8-8cbd-4d12-bad9-3a5a017dbe96 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c04db9a8-8cbd-4d12-bad9-3a5a017dbe96');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Validation Set - Report\n","Validation Weighted Accuracy 0.9401417327679762\n"]},{"output_type":"display_data","data":{"text/plain":["   Precision  Recall  F1 - Score  Accuracy - Category wise  \\\n","0       0.96    0.97        0.96                      0.97   \n","1       0.97    0.97        0.97                      0.97   \n","2       0.94    0.93        0.93                      0.93   \n","3       0.94    0.91        0.92                      0.91   \n","4       0.94    0.95        0.94                      0.95   \n","5       0.91    0.91        0.91                      0.91   \n","6       0.96    0.97        0.97                      0.97   \n","7       0.95    0.94        0.95                      0.94   \n","8       0.91    0.93        0.92                      0.93   \n","9       0.91    0.92        0.91                      0.92   \n","\n","   Count - Category wise  \n","0                 1175.0  \n","1                 1322.0  \n","2                 1174.0  \n","3                 1219.0  \n","4                 1176.0  \n","5                 1104.0  \n","6                 1177.0  \n","7                 1299.0  \n","8                 1160.0  \n","9                 1194.0  "],"text/html":["\n","  <div id=\"df-fc23b64f-5a76-423c-bd98-9453bf513ef0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 - Score</th>\n","      <th>Accuracy - Category wise</th>\n","      <th>Count - Category wise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.96</td>\n","      <td>0.97</td>\n","      <td>0.96</td>\n","      <td>0.97</td>\n","      <td>1175.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.97</td>\n","      <td>0.97</td>\n","      <td>0.97</td>\n","      <td>0.97</td>\n","      <td>1322.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.94</td>\n","      <td>0.93</td>\n","      <td>0.93</td>\n","      <td>0.93</td>\n","      <td>1174.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.94</td>\n","      <td>0.91</td>\n","      <td>0.92</td>\n","      <td>0.91</td>\n","      <td>1219.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.94</td>\n","      <td>0.95</td>\n","      <td>0.94</td>\n","      <td>0.95</td>\n","      <td>1176.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.91</td>\n","      <td>0.91</td>\n","      <td>0.91</td>\n","      <td>0.91</td>\n","      <td>1104.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.96</td>\n","      <td>0.97</td>\n","      <td>0.97</td>\n","      <td>0.97</td>\n","      <td>1177.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.95</td>\n","      <td>0.94</td>\n","      <td>0.95</td>\n","      <td>0.94</td>\n","      <td>1299.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.91</td>\n","      <td>0.93</td>\n","      <td>0.92</td>\n","      <td>0.93</td>\n","      <td>1160.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.91</td>\n","      <td>0.92</td>\n","      <td>0.91</td>\n","      <td>0.92</td>\n","      <td>1194.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc23b64f-5a76-423c-bd98-9453bf513ef0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fc23b64f-5a76-423c-bd98-9453bf513ef0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fc23b64f-5a76-423c-bd98-9453bf513ef0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Test Set - Report\n","Test Weighted Accuracy 0.939757711386582\n"]},{"output_type":"display_data","data":{"text/plain":["   Precision  Recall  F1 - Score  Accuracy - Category wise  \\\n","0       0.95    0.97        0.96                      0.97   \n","1       0.97    0.98        0.98                      0.98   \n","2       0.94    0.94        0.94                      0.94   \n","3       0.91    0.93        0.92                      0.93   \n","4       0.94    0.96        0.95                      0.96   \n","5       0.91    0.90        0.91                      0.90   \n","6       0.95    0.95        0.95                      0.95   \n","7       0.96    0.93        0.95                      0.93   \n","8       0.92    0.92        0.92                      0.92   \n","9       0.94    0.91        0.93                      0.91   \n","\n","   Count - Category wise  \n","0                  980.0  \n","1                 1135.0  \n","2                 1032.0  \n","3                 1010.0  \n","4                  982.0  \n","5                  892.0  \n","6                  958.0  \n","7                 1028.0  \n","8                  974.0  \n","9                 1009.0  "],"text/html":["\n","  <div id=\"df-0ad255d4-14bd-45d1-b6b7-1908a4d2beea\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1 - Score</th>\n","      <th>Accuracy - Category wise</th>\n","      <th>Count - Category wise</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.95</td>\n","      <td>0.97</td>\n","      <td>0.96</td>\n","      <td>0.97</td>\n","      <td>980.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.97</td>\n","      <td>0.98</td>\n","      <td>0.98</td>\n","      <td>0.98</td>\n","      <td>1135.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.94</td>\n","      <td>0.94</td>\n","      <td>0.94</td>\n","      <td>0.94</td>\n","      <td>1032.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.91</td>\n","      <td>0.93</td>\n","      <td>0.92</td>\n","      <td>0.93</td>\n","      <td>1010.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.94</td>\n","      <td>0.96</td>\n","      <td>0.95</td>\n","      <td>0.96</td>\n","      <td>982.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.91</td>\n","      <td>0.90</td>\n","      <td>0.91</td>\n","      <td>0.90</td>\n","      <td>892.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>0.95</td>\n","      <td>0.95</td>\n","      <td>0.95</td>\n","      <td>0.95</td>\n","      <td>958.0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>0.96</td>\n","      <td>0.93</td>\n","      <td>0.95</td>\n","      <td>0.93</td>\n","      <td>1028.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0.92</td>\n","      <td>0.92</td>\n","      <td>0.92</td>\n","      <td>0.92</td>\n","      <td>974.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>0.94</td>\n","      <td>0.91</td>\n","      <td>0.93</td>\n","      <td>0.91</td>\n","      <td>1009.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0ad255d4-14bd-45d1-b6b7-1908a4d2beea')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0ad255d4-14bd-45d1-b6b7-1908a4d2beea button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0ad255d4-14bd-45d1-b6b7-1908a4d2beea');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["print('Training Set - Report')\n","print(f'Train Weighted Accuracy {train_weighted_acc}')\n","display(df_result_train)\n","print('Validation Set - Report')\n","print(f'Validation Weighted Accuracy {val_weighted_acc}')\n","display(df_result_validation)\n","print('Test Set - Report')\n","print(f'Test Weighted Accuracy {test_weighted_acc}')\n","display(df_result_test)"]},{"cell_type":"markdown","id":"OV6MNzNUDqBx","metadata":{"id":"OV6MNzNUDqBx"},"source":["\n","15. Now, we will do the same exercise with sklearn. Use the MLPClassifier class from sklearn. Using this class, keep\n","the architecture of the hidden layers as the same as previously mentioned in point 8. Sklearn automatically adjusts\n","and recognises the input sizes for the input and output layer of the neural network. Use relu as the activation for all\n","layers and use the random_state value as 42. Do not change any other parameters of the class"]},{"cell_type":"code","execution_count":18,"id":"94WVkTx7-L6m","metadata":{"id":"94WVkTx7-L6m","executionInfo":{"status":"ok","timestamp":1679117391312,"user_tz":-330,"elapsed":13,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["mlp = MLPClassifier(hidden_layer_sizes=(16,32,16,10), activation='relu', random_state=seed)"]},{"cell_type":"markdown","id":"E8D81J0XD8i_","metadata":{"id":"E8D81J0XD8i_"},"source":["16. Fit the class to the X_train and Y_train data.\n"]},{"cell_type":"code","execution_count":19,"id":"IByHbtb5D3qo","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":129},"id":"IByHbtb5D3qo","outputId":"fbbb65ae-2fd1-4af3-d265-7fca4acb1ec9","executionInfo":{"status":"ok","timestamp":1679117527273,"user_tz":-330,"elapsed":135973,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["MLPClassifier(hidden_layer_sizes=(16, 32, 16, 10), random_state=42)"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(16, 32, 16, 10), random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(hidden_layer_sizes=(16, 32, 16, 10), random_state=42)</pre></div></div></div></div></div>"]},"metadata":{},"execution_count":19}],"source":["mlp.fit(X_train, Y_train)"]},{"cell_type":"markdown","id":"beRWm78EECJR","metadata":{"id":"beRWm78EECJR"},"source":["17. Use the fitted class to make predictions on the three datasets mentioned in point 13.\n"]},{"cell_type":"code","execution_count":20,"id":"-byWdiTnD3jc","metadata":{"id":"-byWdiTnD3jc","executionInfo":{"status":"ok","timestamp":1679117527274,"user_tz":-330,"elapsed":31,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":["y_train_prediction = mlp.predict(X_train)\n","y_val_prediction = mlp.predict(X_val)\n","y_test_prediction = mlp.predict(X_test)"]},{"cell_type":"markdown","id":"xfvyjTJFEO4x","metadata":{"id":"xfvyjTJFEO4x"},"source":["18. Create classification reports using sklearn.metrics.classification_report for the different sets of predictions.\n"]},{"cell_type":"code","execution_count":21,"id":"N_F2ECGTEDvl","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N_F2ECGTEDvl","outputId":"ff726f7c-fc71-43e4-86f3-3ebc26bc74ef","executionInfo":{"status":"ok","timestamp":1679117527275,"user_tz":-330,"elapsed":31,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      1.00      4748\n","           1       0.99      1.00      1.00      5420\n","           2       0.99      0.99      0.99      4784\n","           3       0.99      0.99      0.99      4912\n","           4       1.00      1.00      1.00      4666\n","           5       1.00      0.99      0.99      4317\n","           6       0.99      1.00      0.99      4741\n","           7       1.00      1.00      1.00      4966\n","           8       1.00      0.99      1.00      4691\n","           9       1.00      0.99      1.00      4755\n","\n","   micro avg       1.00      1.00      1.00     48000\n","   macro avg       1.00      1.00      1.00     48000\n","weighted avg       1.00      1.00      1.00     48000\n"," samples avg       0.99      1.00      0.99     48000\n","\n","\n","\n","Valdiation\n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.96      0.97      1175\n","           1       0.97      0.98      0.98      1322\n","           2       0.93      0.95      0.94      1174\n","           3       0.92      0.94      0.93      1219\n","           4       0.94      0.96      0.95      1176\n","           5       0.95      0.92      0.93      1104\n","           6       0.95      0.96      0.96      1177\n","           7       0.96      0.95      0.95      1299\n","           8       0.93      0.91      0.92      1160\n","           9       0.94      0.93      0.93      1194\n","\n","   micro avg       0.95      0.95      0.95     12000\n","   macro avg       0.95      0.95      0.95     12000\n","weighted avg       0.95      0.95      0.95     12000\n"," samples avg       0.94      0.95      0.94     12000\n","\n","\n","\n","Test\n","              precision    recall  f1-score   support\n","\n","           0       0.96      0.97      0.97       980\n","           1       0.98      0.98      0.98      1135\n","           2       0.93      0.96      0.94      1032\n","           3       0.91      0.95      0.93      1010\n","           4       0.95      0.96      0.95       982\n","           5       0.94      0.92      0.93       892\n","           6       0.96      0.94      0.95       958\n","           7       0.95      0.94      0.94      1028\n","           8       0.95      0.91      0.93       974\n","           9       0.94      0.93      0.94      1009\n","\n","   micro avg       0.95      0.95      0.95     10000\n","   macro avg       0.95      0.95      0.95     10000\n","weighted avg       0.95      0.95      0.95     10000\n"," samples avg       0.94      0.95      0.94     10000\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["print('Train')\n","print(classification_report(Y_train, y_train_prediction, digits=round_precesion))\n","print('\\n\\nValdiation')\n","print(classification_report(Y_val, y_val_prediction, digits=round_precesion))\n","print('\\n\\nTest')\n","print(classification_report(Y_test, y_test_prediction, digits=round_precesion))"]},{"cell_type":"markdown","source":["Looking at the results of MLP classifier and our own pytorch version of ANN we are getting almost same result in terms of target label wise accuracy and weighted accuracy on the overall datset. This clearly depicts that sklearn MLPClassifier and ANN classifier created using pytorch are approximately equivalent in terms of performace."],"metadata":{"id":"KAlUdgu9KzIq"},"id":"KAlUdgu9KzIq"},{"cell_type":"code","execution_count":21,"id":"o2VxhbNbEDoQ","metadata":{"id":"o2VxhbNbEDoQ","executionInfo":{"status":"ok","timestamp":1679117527275,"user_tz":-330,"elapsed":28,"user":{"displayName":"MTech IITM","userId":"11434530727453000419"}}},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"toc_visible":true},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":5}